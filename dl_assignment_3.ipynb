{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8268677,
          "sourceType": "datasetVersion",
          "datasetId": 4908887
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-12T13:30:23.625061Z",
          "iopub.execute_input": "2024-05-12T13:30:23.625380Z",
          "iopub.status.idle": "2024-05-12T13:30:24.444734Z",
          "shell.execute_reply.started": "2024-05-12T13:30:23.625355Z",
          "shell.execute_reply": "2024-05-12T13:30:24.443780Z"
        },
        "trusted": true,
        "id": "JYPooyJCM4nS",
        "outputId": "41010c3e-fe72-4116-a63e-821167962fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/aksharantardataset/aksharantar_sampled/brx/brx_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/brx/brx_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/brx/brx_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/tam/tam_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/tam/tam_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/tam/tam_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/mni/mni_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/mni/mni_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/mni/mni_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/urd/urd_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/urd/urd_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/urd/urd_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/kok/kok_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/kok/kok_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/kok/kok_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/mai/mai_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/mai/mai_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/mai/mai_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/guj/guj_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/guj/guj_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/guj/guj_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/ben/ben_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/ben/ben_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/ben/ben_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/tel/tel_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/tel/tel_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/tel/tel_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/kas/kas_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/kas/kas_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/kas/kas_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/kan/kan_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/kan/kan_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/kan/kan_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/mal/mal_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/mal/mal_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/mal/mal_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/pan/pan_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/pan/pan_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/pan/pan_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/asm/asm_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/asm/asm_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/asm/asm_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/sid/sid_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/sid/sid_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/sid/sid_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/mar/mar_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/mar/mar_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/mar/mar_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/san/san_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/san/san_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/san/san_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/hin/hin_valid.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/hin/hin_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/hin/hin_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/ori/ori_test.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/ori/ori_train.csv\n/kaggle/input/aksharantardataset/aksharantar_sampled/ori/ori_valid.csv\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets,transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import pandas as pd\n",
        "import random"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T13:30:24.446679Z",
          "iopub.execute_input": "2024-05-12T13:30:24.447496Z",
          "iopub.status.idle": "2024-05-12T13:30:42.710982Z",
          "shell.execute_reply.started": "2024-05-12T13:30:24.447463Z",
          "shell.execute_reply": "2024-05-12T13:30:42.709913Z"
        },
        "trusted": true,
        "id": "GNWPpv0GM4nT",
        "outputId": "1213eea5-4115-444d-ffcb-926b651caa58"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.1.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchvision) (1.3.0)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "#device selection CPU or GPU\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T13:30:42.712277Z",
          "iopub.execute_input": "2024-05-12T13:30:42.713029Z",
          "iopub.status.idle": "2024-05-12T13:30:42.766655Z",
          "shell.execute_reply.started": "2024-05-12T13:30:42.712996Z",
          "shell.execute_reply": "2024-05-12T13:30:42.765660Z"
        },
        "trusted": true,
        "id": "MOsNE-sXM4nT",
        "outputId": "310ee45c-5703-4833-b910-cd3266df1e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "cuda\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_root='/kaggle/input/aksharantardataset/aksharantar_sampled/tel/tel_train.csv'\n",
        "valid_data_root='/kaggle/input/aksharantardataset/aksharantar_sampled/tel/tel_valid.csv'\n",
        "test_data_root='/kaggle/input/aksharantardataset/aksharantar_sampled/tel/tel_test.csv'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T13:30:42.768792Z",
          "iopub.execute_input": "2024-05-12T13:30:42.769697Z",
          "iopub.status.idle": "2024-05-12T13:30:42.774884Z",
          "shell.execute_reply.started": "2024-05-12T13:30:42.769669Z",
          "shell.execute_reply": "2024-05-12T13:30:42.774004Z"
        },
        "trusted": true,
        "id": "zmSR0ZfIM4nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=pd.read_csv(train_data_root,header=None)\n",
        "valid_data=pd.read_csv(valid_data_root,header=None)\n",
        "test_data=pd.read_csv(test_data_root,header=None)\n",
        "print(train_data[0][1])\n",
        "eng_list_train=train_data[0]\n",
        "tel_list_train=train_data[1]\n",
        "eng_list_valid=valid_data[0]\n",
        "tel_list_valid=valid_data[1]\n",
        "eng_list_test=test_data[0]\n",
        "tel_list_test=test_data[1]\n",
        "print(tel_list_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T13:30:42.775977Z",
          "iopub.execute_input": "2024-05-12T13:30:42.776233Z",
          "iopub.status.idle": "2024-05-12T13:30:42.925522Z",
          "shell.execute_reply.started": "2024-05-12T13:30:42.776211Z",
          "shell.execute_reply": "2024-05-12T13:30:42.924621Z"
        },
        "trusted": true,
        "id": "xrGmsA5sM4nU",
        "outputId": "305da67c-1256-4a1e-9e57-a35034172eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "vastadira\n0              వర్గాలవారినే\n1                 వస్తాదిరా\n2             ఫ్యాక్టమ్ఫోస్\n3                మూత్రనాళాల\n4                 ద్విపాత్ర\n                ...        \n51195          తెలుస్తోందవి\n51196               పేచింగ్\n51197    వెనక్కితీసుకోవాలనే\n51198            రూపాంతరాలు\n51199           చెందిందింది\nName: 1, Length: 51200, dtype: object\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_vocab=[] #list of the letters in the english words\n",
        "tel_vocab=[] #list of the letters in the telugu words\n",
        "max_eng_len=-1\n",
        "max_tel_len=-1\n",
        "max_eng_word=\"\"\n",
        "max_tel_word=\"\"\n",
        "for word in eng_list_train:\n",
        "    max_eng_len=max(max_eng_len,len(word))\n",
        "    if(max_eng_len==len(word)):\n",
        "        max_eng_word=word\n",
        "    for letter in word:\n",
        "        eng_vocab.append(letter)\n",
        "eng_vocab=list(set(eng_vocab))\n",
        "eng_vocab.sort()\n",
        "\n",
        "for word in tel_list_train:\n",
        "    max_tel_len=max(max_tel_len,len(word))\n",
        "    if(max_tel_len==len(word)):\n",
        "        max_tel_word=word\n",
        "    for letter in word:\n",
        "        tel_vocab.append(letter)\n",
        "tel_vocab=list(set(tel_vocab))\n",
        "tel_vocab.sort()\n",
        "\n",
        "for word in eng_list_valid:\n",
        "    max_eng_len=max(max_eng_len,len(word))\n",
        "for word in eng_list_test:\n",
        "    max_eng_len=max(max_eng_len,len(word))\n",
        "for word in tel_list_test:\n",
        "    max_tel_len=max(max_tel_len,len(word))\n",
        "for word in tel_list_valid:\n",
        "    max_tel_len=max(max_tel_len,len(word))\n",
        "print(tel_vocab)\n",
        "print(eng_vocab)\n",
        "print(len(max_tel_word))\n",
        "print(len(max_eng_word))\n",
        "print(max_tel_len,max_eng_len)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T13:30:42.926802Z",
          "iopub.execute_input": "2024-05-12T13:30:42.927127Z",
          "iopub.status.idle": "2024-05-12T13:30:43.256639Z",
          "shell.execute_reply.started": "2024-05-12T13:30:42.927103Z",
          "shell.execute_reply": "2024-05-12T13:30:43.255792Z"
        },
        "trusted": true,
        "id": "-iUQ8T2oM4nU",
        "outputId": "f2df164a-02eb-48e6-a3a1-0d9da6257132"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "['ం', 'ః', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'క', 'ఖ', 'గ', 'ఘ', 'చ', 'ఛ', 'జ', 'ఝ', 'ఞ', 'ట', 'ఠ', 'డ', 'ఢ', 'ణ', 'త', 'థ', 'ద', 'ధ', 'న', 'ప', 'ఫ', 'బ', 'భ', 'మ', 'య', 'ర', 'ఱ', 'ల', 'ళ', 'వ', 'శ', 'ష', 'స', 'హ', 'ా', 'ి', 'ీ', 'ు', 'ూ', 'ృ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', '్']\n['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n21\n28\n21 28\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert the telugu or english word to a vectorial representation\n",
        "def word_to_vector(language,word):\n",
        "    vec=[]\n",
        "    if(language==\"english\"):\n",
        "        vec.append(len(eng_vocab)+1)\n",
        "        for letter in word:\n",
        "            for albt in range(len(eng_vocab)):\n",
        "                if(eng_vocab[albt]==letter):\n",
        "                    vec.append(albt+1)\n",
        "        while(len(vec)<(max_eng_len+1)):\n",
        "            vec.append(0)\n",
        "        vec.append(0)\n",
        "    else:\n",
        "        vec.append(len(tel_vocab)+1)\n",
        "        for letter in word:\n",
        "            for albt in range(len(tel_vocab)):\n",
        "                if(tel_vocab[albt]==letter):\n",
        "                    vec.append(albt+1)\n",
        "        while(len(vec)<(max_tel_len+1)):\n",
        "            vec.append(0)\n",
        "        vec.append(0)\n",
        "    return vec\n",
        "print(word_to_vector(\"english\",eng_list_train[1]))\n",
        "print(word_to_vector(\"telugu\",tel_list_train[1]))\n",
        "print(len(word_to_vector(\"english\",eng_list_train[1])))\n",
        "print(len(word_to_vector(\"telugu\",tel_list_train[1])))\n",
        "print(eng_list_train[1])\n",
        "print(tel_list_train[1])\n",
        "# print(eng_list_train.shape)\n",
        "print(len(eng_vocab))\n",
        "print(len(tel_vocab))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T13:30:43.257609Z",
          "iopub.execute_input": "2024-05-12T13:30:43.257864Z",
          "iopub.status.idle": "2024-05-12T13:30:43.268212Z",
          "shell.execute_reply.started": "2024-05-12T13:30:43.257830Z",
          "shell.execute_reply": "2024-05-12T13:30:43.267426Z"
        },
        "trusted": true,
        "id": "qm2_hXdMM4nU",
        "outputId": "483aec3e-c920-4df0-bb7e-92432f4c64cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[27, 22, 1, 19, 20, 1, 4, 9, 18, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[63, 45, 48, 62, 30, 50, 32, 51, 41, 50, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n30\n23\nvastadira\nవస్తాదిరా\n26\n62\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creation of the matrix for the english and the telugu words\n",
        "\n",
        "# for training data\n",
        "eng_matrix_train=[]\n",
        "for word in eng_list_train:\n",
        "    eng_matrix_train.append(word_to_vector(\"english\",word))\n",
        "tel_matrix_train=[]\n",
        "for word in tel_list_train:\n",
        "    tel_matrix_train.append(word_to_vector(\"telugu\",word))\n",
        "eng_matrix_train=torch.tensor(eng_matrix_train)\n",
        "tel_matrix_train=torch.tensor(tel_matrix_train)\n",
        "print(eng_matrix_train[1])\n",
        "print(tel_matrix_train[1])\n",
        "print(eng_list_train[1])\n",
        "print(tel_list_train[1])\n",
        "\n",
        "\n",
        "#for validation data\n",
        "eng_matrix_valid=[]\n",
        "tel_matrix_valid=[]\n",
        "for word in eng_list_valid:\n",
        "    eng_matrix_valid.append(word_to_vector(\"english\",word))\n",
        "for word in tel_list_valid:\n",
        "    tel_matrix_valid.append(word_to_vector(\"telugu\",word))\n",
        "eng_matrix_valid=torch.tensor(eng_matrix_valid)\n",
        "tel_matrix_valid=torch.tensor(tel_matrix_valid)\n",
        "print(eng_matrix_valid[1])\n",
        "print(tel_matrix_valid[1])\n",
        "print(eng_list_valid[1])\n",
        "print(tel_list_valid[1])\n",
        "\n",
        "\n",
        "# for test data\n",
        "eng_matrix_test=[]\n",
        "tel_matrix_test=[]\n",
        "for word in eng_list_test:\n",
        "    eng_matrix_test.append(word_to_vector(\"english\",word))\n",
        "for word in tel_list_test:\n",
        "    tel_matrix_test.append(word_to_vector(\"telugu\",word))\n",
        "eng_matrix_test=torch.tensor(eng_matrix_test) # converted to tensors for the tensor feasible applications\n",
        "tel_matrix_test=torch.tensor(tel_matrix_test)\n",
        "print(eng_matrix_test[1])\n",
        "print(tel_matrix_test[1])\n",
        "print(eng_list_test[1])\n",
        "print(tel_list_test[1])\n",
        "\n",
        "\n",
        "print(len(eng_matrix_train))\n",
        "print(len(eng_matrix_valid))\n",
        "print(len(eng_matrix_test))\n",
        "print(tel_matrix_train.shape)\n",
        "print(eng_matrix_train.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T13:30:43.269619Z",
          "iopub.execute_input": "2024-05-12T13:30:43.270410Z",
          "iopub.status.idle": "2024-05-12T13:30:51.149318Z",
          "shell.execute_reply.started": "2024-05-12T13:30:43.270386Z",
          "shell.execute_reply": "2024-05-12T13:30:51.148395Z"
        },
        "trusted": true,
        "id": "wUJTyMpeM4nU",
        "outputId": "6d5d2559-a044-4b77-bbdc-7619e235c504"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor([27, 22,  1, 19, 20,  1,  4,  9, 18,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\ntensor([63, 45, 48, 62, 30, 50, 32, 51, 41, 50,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0])\nvastadira\nవస్తాదిరా\ntensor([27, 22,  9, 14, 25,  1, 19,  1,  1, 14, 14,  9,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\ntensor([63, 45, 51, 34, 62, 40, 50, 48, 50, 34, 62, 34, 51,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0])\nvinyasaanni\nవిన్యాసాన్ని\ntensor([27, 16, 18,  1, 25,  1,  1, 14,  9, 11, 21, 12, 21,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\ntensor([63, 35, 62, 41, 40, 50, 29, 51, 16, 53, 43, 53,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0])\nprayaanikulu\nప్రయాణికులు\n51200\n4096\n4096\ntorch.Size([51200, 23])\ntorch.Size([51200, 30])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder class for the input and producing the output as the input for the decoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,input_size,embedding_size,enc_layers,hidden_size,cell_type,bi_directional_bit,dropout):\n",
        "        super(Encoder,self).__init__()\n",
        "        self.input_size=input_size\n",
        "        self.embedding_size=embedding_size\n",
        "        self.enc_layers=enc_layers\n",
        "        self.dec_layers=dec_layers\n",
        "        self.cell_type=cell_type\n",
        "        self.bi_directional_bit=bi_directional_bit\n",
        "        self.dropout=nn.Dropout(dropout)\n",
        "        self.embedding=nn.Embedding(input_size,embedding_size)\n",
        "        self.hidden_size=hidden_size\n",
        "        self.batch_size=batch_size\n",
        "        #based on the type of the cell considering the variant of the neural network to be used\n",
        "        if(cell_type==\"RNN\"):\n",
        "            self.rnn=nn.RNN(embedding_size,hidden_size,enc_layers,dropout=dropout,bidirectional=bi_directional_bit)\n",
        "        elif(cell_type==\"GRU\"):\n",
        "            self.gru=nn.GRU(embedding_size,hidden_size,enc_layers,dropout=dropout,bidirectional=bi_directional_bit)\n",
        "        else:\n",
        "            self.lstm=nn.LSTM(embedding_size,hidden_size,enc_layers,dropout=dropout,bidirectional=bi_directional_bit)\n",
        "\n",
        "\n",
        "\n",
        "    #forward passing\n",
        "    def forward(self,x,hidden,cell):\n",
        "        embedding=self.embedding(x).view(-1,self.batch_size,self.embedding_size)\n",
        "        embedding=self.dropout(embedding) # adding the dropout at the input layer\n",
        "        if(cell_type==\"RNN\"):\n",
        "            output,hidden=self.rnn(embedding,hidden)\n",
        "        elif(cell_type==\"GRU\"):\n",
        "            output,hidden=self.gru(embedding,hidden)\n",
        "        else:\n",
        "            output,(hidden,cell)=self.lstm(embedding,(hidden,cell))\n",
        "            return output,hidden,cell\n",
        "        return output,hidden\n",
        "\n",
        "    # initialize the tensor to zeroes at start\n",
        "    def initialize_hidden(self):\n",
        "        if(self.bi_directional_bit==True):\n",
        "            return torch.zeros(2*self.enc_layers,self.batch_size,self.hidden_size,device=device)\n",
        "        return torch.zeros(self.enc_layers,self.batch_size,self.hidden_size,device=device)\n",
        "    def initialize_cell(self):\n",
        "        if(self.bi_directional_bit==True):\n",
        "            return torch.zeros(2*self.enc_layers,self.batch_size,self.hidden_size,device=device)\n",
        "        return torch.zeros(self.enc_layers,self.batch_size,self.hidden_size,device=device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T13:30:51.150562Z",
          "iopub.execute_input": "2024-05-12T13:30:51.150932Z",
          "iopub.status.idle": "2024-05-12T13:30:51.164125Z",
          "shell.execute_reply.started": "2024-05-12T13:30:51.150901Z",
          "shell.execute_reply": "2024-05-12T13:30:51.163173Z"
        },
        "trusted": true,
        "id": "uOmUPYoMM4nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#declearing the decoder class\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,input_size,embedding_size,hidden_size,dec_layers,dropout,cell_type,output_size):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.input_size=input_size\n",
        "        self.embedding_size=embedding_size\n",
        "        self.hidden_size=hidden_size\n",
        "        self.dec_layers=dec_layers\n",
        "        self.dropout=nn.Dropout(dropout)\n",
        "        self.cell_type=cell_type\n",
        "        self.embedding=nn.Embedding(input_size,embedding_size)\n",
        "        if(cell_type==\"RNN\"):\n",
        "            self.rnn=nn.RNN(embedding_size,hidden_size,dec_layers,dropout=dropout)\n",
        "        elif(cell_type==\"GRU\"):\n",
        "            self.gru=nn.GRU(embedding_size,hidden_size,dec_layers,dropout=dropout)\n",
        "        else:\n",
        "            self.lstm=nn.LSTM(embedding_size,hidden_size,dec_layers,dropout=dropout)\n",
        "        self.fully_conc=nn.Linear(hidden_size,output_size)\n",
        "\n",
        "    # forward pass\n",
        "    def forward(self,x,prev_output,prev_hidden,cell=0):\n",
        "        x=x.unsqueeze(0).int() # convert the input token X to tensor and gives a single dimension\n",
        "        embedding=self.embedding(x)\n",
        "        embedding=self.dropout(embedding)\n",
        "        if(cell_type==\"RNN\"):\n",
        "            outputs,hidden=self.rnn(embedding,prev_hidden)\n",
        "        elif(cell_type==\"GRU\"):\n",
        "            outputs,hidden=self.gru(embedding,prev_hidden)\n",
        "        else:\n",
        "            outputs,(hidden,cell)=self.lstm(embedding,(prev_hidden,cell))\n",
        "\n",
        "        #as we converted it by using unsqueezing the dimension of the output is like(1,N,hidden_size)\n",
        "        pred=self.fully_conc(outputs)\n",
        "        # this makes the dimension as the (1,N,size_of_vocab)\n",
        "        pred=pred.squeeze(0)\n",
        "        # this makes the dimension as the (N,size_of_vocab)\n",
        "        if(cell_type==\"GRU\" or cell_type == \"RNN\"):\n",
        "            return pred,hidden\n",
        "        return pred,hidden,cell\n",
        "\n",
        "\n",
        "    #initialize the tensor to zeroes\n",
        "    def initialize_hidden(self):\n",
        "        return torch.zeros(self.dec_layers,self.batch_size,self.hidden_size,device=device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T13:30:51.167971Z",
          "iopub.execute_input": "2024-05-12T13:30:51.168557Z",
          "iopub.status.idle": "2024-05-12T13:30:51.181067Z",
          "shell.execute_reply.started": "2024-05-12T13:30:51.168532Z",
          "shell.execute_reply": "2024-05-12T13:30:51.180127Z"
        },
        "trusted": true,
        "id": "gJs6KnBNM4nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class attention_add_decoder(nn.Module):\n",
        "    def __init__(self,input_size,embedding_size,hidden_size,output_size,cell_type,dec_layers,dropout,bi_directional_bit):\n",
        "        super(attention_add_decoder,self).__init__()\n",
        "        self.input_size=input_size\n",
        "        self.hidden_size=hidden_size\n",
        "        self.output_size=output_size\n",
        "        self.cell_type=cell_type\n",
        "        self.dec_layers=dec_layers\n",
        "        self.bi_directional_bit=bi_directional_bit\n",
        "        self.cell_type=cell_type\n",
        "        self.embedding_size=embedding_size\n",
        "        self.dropout=nn.Dropout(dropout)\n",
        "        self.length=len(eng_matrix_train[0])\n",
        "        self.embedding=nn.Embedding(input_size,embedding_size)\n",
        "        if(self.cell_type==\"LSTM\"):\n",
        "            self.lstm=nn.LSTM(hidden_size,hidden_size,dec_layers,dropout=dropout)\n",
        "        elif(self.cell_type==\"GRU\"):\n",
        "            self.gru=nn.GRU(hidden_size,hidden_size,dec_layers,dropout=dropout)\n",
        "        else:\n",
        "            self.rnn=nn.RNN(hidden_size,hidden_size,dec_layers,dropout=dropout)\n",
        "        self.fully_conc=nn.Linear(hidden_size,output_size)\n",
        "        self.attention=nn.Linear(hidden_size+embedding_size,self.length)\n",
        "        if(bi_directional_bit==True):\n",
        "            self.atten_adding=nn.Linear(hidden_size*2+embedding_size,hidden_size)\n",
        "        elif(bi_directional_bit==False):\n",
        "            self.atten_adding=nn.Linear(hidden_size+embedding_size,hidden_size)\n",
        "\n",
        "    def forward(self,x,prev_output,prev_hidden,cell=0):\n",
        "        prev_output = prev_output.permute(1,0,2) #this will help to rearrange the dimensions to 1,0,2\n",
        "        x=x.unsqueeze(0)\n",
        "        embedded=self.dropout(self.embedding(x))\n",
        "        cnct=torch.cat((embedded[0],prev_hidden[0]),1)\n",
        "        atten_parameters=func.softmax(self.attention(cnct),dim=1)\n",
        "        atten_added=torch.bmm(atten_parameters.unsqueeze(1),prev_output) # this performs a batch wise matrix multiplications4\n",
        "        atten_added=atten_added.squeeze(1)\n",
        "#         print(\"Hello\")\n",
        "#         print(\"shape of embedded[0] is: \",embedded[0].shape)\n",
        "#         print(\"shape of atten_added is: \",atten_added.shape)\n",
        "        final_output=torch.cat((embedded[0],atten_added),1)\n",
        "        final_output=torch.unsqueeze(self.atten_adding(final_output),0)\n",
        "        final_output=func.relu(final_output)\n",
        "\n",
        "        if(cell_type==\"RNN\"):\n",
        "            outputs,hidden=self.rnn(final_output,prev_hidden)\n",
        "        elif(cell_type==\"GRU\"):\n",
        "            outputs,hidden=self.gru(final_output,prev_hidden)\n",
        "        else:\n",
        "            outputs,(hidden,cell)=self.lstm(final_output,(prev_hidden,cell))\n",
        "\n",
        "        pred= self.fully_conc(outputs)\n",
        "        pred= pred.squeeze(0)\n",
        "        if(self.cell_type==\"GRU\" or self.cell_type==\"RNN\"):\n",
        "            return pred,hidden\n",
        "        else:\n",
        "            return pred,hidden,cell"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T13:30:51.182154Z",
          "iopub.execute_input": "2024-05-12T13:30:51.182460Z",
          "iopub.status.idle": "2024-05-12T13:30:51.199199Z",
          "shell.execute_reply.started": "2024-05-12T13:30:51.182435Z",
          "shell.execute_reply": "2024-05-12T13:30:51.198315Z"
        },
        "trusted": true,
        "id": "TyBxmeOaM4nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq_to_seq(nn.Module):\n",
        "    def __init__(self,decoder,encoder,cell_type,bidirectional_bit,encoder_layers,decoder_layers):\n",
        "        super(Seq_to_seq,self).__init__()\n",
        "        self.decoder=decoder\n",
        "        self.encoder=encoder\n",
        "        self.cell_type=cell_type\n",
        "        self.bidirectional_bit=bidirectional_bit\n",
        "        self.encoder_layers=encoder_layers\n",
        "        self.decoder_layers=decoder_layers\n",
        "\n",
        "    #forward pass\n",
        "    def forward(self,input_seq,target,teacher_force_ratio=0.5):\n",
        "        batch_size=input_seq.shape[1]\n",
        "        tar_seq_length=target.shape[0]\n",
        "        final_target_vocab_size=len(tel_vocab)+2 #this +2 will help the model for the additional special tokens\n",
        "        outputs=torch.zeros(tar_seq_length,batch_size,final_target_vocab_size).to(device=device)\n",
        "        hidden=self.encoder.initialize_hidden()\n",
        "        cell=self.encoder.initialize_cell()\n",
        "        if(self.cell_type==\"RNN\" or self.cell_type==\"GRU\"):\n",
        "            encoder_output,hidden=self.encoder(input_seq,hidden,cell)\n",
        "        else:\n",
        "            encoder_output,hidden,cell=self.encoder(input_seq,hidden,cell)\n",
        "        if(self.decoder_layers!=self.encoder_layers or self.bidirectional_bit):\n",
        "            if(self.cell_type==\"RNN\" or self.cell_type==\"GRU\"):\n",
        "                hidden=hidden[self.encoder_layers-1]+hidden[self.encoder_layers-1]\n",
        "                hidden=hidden.repeat(self.decoder_layers,1,1)\n",
        "            if(self.cell_type==\"LSTM\"):\n",
        "                cell=cell[self.encoder_layers-1]+cell[self.encoder_layers-1]\n",
        "                cell=cell.repeat(self.decoder_layers,1,1)\n",
        "        x=target[0]\n",
        "        for t in range(1,tar_seq_length):\n",
        "            if(cell_type==\"RNN\" or cell_type==\"GRU\"):\n",
        "                output,hidden=self.decoder(x,encoder_output,hidden)\n",
        "            else:\n",
        "                output,hidden,cell=self.decoder(x,encoder_output,hidden,cell)\n",
        "            outputs[t]=output\n",
        "            predicted=output.argmax(1)\n",
        "            if(random.random()<teacher_force_ratio):\n",
        "                x=target[t]\n",
        "            else:\n",
        "                x=predicted\n",
        "        return outputs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T13:30:51.200586Z",
          "iopub.execute_input": "2024-05-12T13:30:51.201180Z",
          "iopub.status.idle": "2024-05-12T13:30:51.214380Z",
          "shell.execute_reply.started": "2024-05-12T13:30:51.201149Z",
          "shell.execute_reply": "2024-05-12T13:30:51.213450Z"
        },
        "trusted": true,
        "id": "oquZ57AAM4nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recurrent_neural_network(cell_type, bi_directional_bit, embedding_size, enc_dropout, dec_dropout, enc_layers, dec_layers, hidden_size, batch_size, attention, learning_rate, max_epochs,attention_bit):\n",
        "    enc_input_size=len(eng_vocab)+2\n",
        "    dec_input_size=len(tel_vocab)+2\n",
        "    output_size=len(tel_vocab)+2\n",
        "    # encoder network decleration\n",
        "    encoder_section=Encoder(enc_input_size,embedding_size,enc_layers,hidden_size,cell_type,bi_directional_bit,enc_dropout).to(device=device)\n",
        "    # decoder network decleration\n",
        "    if(attention_bit):\n",
        "        decoder_section=attention_add_decoder(dec_input_size,embedding_size,hidden_size,output_size,cell_type,dec_layers,dec_dropout,bi_directional_bit).to(device=device)\n",
        "    else:\n",
        "        decoder_section=Decoder(dec_input_size,embedding_size,hidden_size,dec_layers,dec_dropout,cell_type,output_size).to(device=device)\n",
        "    model=Seq_to_seq(decoder_section,encoder_section,cell_type,bi_directional_bit,enc_layers,dec_layers)\n",
        "    optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n",
        "    pad = len(tel_vocab)+1\n",
        "    loss_criterion=nn.CrossEntropyLoss(ignore_index=pad)\n",
        "#     print(batch_size)\n",
        "    for itr in range(max_epochs):\n",
        "        print(\"epoch: \",itr)\n",
        "\n",
        "        model.train()\n",
        "        final_loss=0\n",
        "        step=0\n",
        "        for batch_id in tqdm(range((int)(len(eng_matrix_train)/batch_size))):\n",
        "            inp_word=eng_matrix_train[batch_size*batch_id:batch_size*(batch_id+1)].to(device=device)\n",
        "            out_word=tel_matrix_train[batch_size*batch_id:batch_size*(batch_id+1)].to(device=device)\n",
        "            out_word=out_word.T\n",
        "            inp_word=inp_word.T\n",
        "            output=model(inp_word,out_word)\n",
        "\n",
        "            output=output[1:].reshape(-1,output.shape[2])\n",
        "            out_word=out_word[1:].reshape(-1)\n",
        "            optimizer.zero_grad()\n",
        "            loss=loss_criterion(output,out_word)\n",
        "            final_loss=final_loss+loss;\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm(model.parameters(),max_norm=1)\n",
        "            optimizer.step()\n",
        "            step=step+1\n",
        "        print(\"total loss: \",final_loss/step)\n",
        "        print(\"train accuracy: \",accuracy_fun(eng_matrix_train,tel_matrix_train,batch_size,max_epochs,model))\n",
        "        print(\"valid accuracy: \",accuracy_fun(eng_matrix_valid,tel_matrix_valid,batch_size,max_epochs,model))\n",
        "        print(\"test accuracy: \",accuracy_fun(eng_matrix_test,tel_matrix_test,batch_size,max_epochs,model))\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T13:30:51.215656Z",
          "iopub.execute_input": "2024-05-12T13:30:51.216049Z",
          "iopub.status.idle": "2024-05-12T13:30:51.231076Z",
          "shell.execute_reply.started": "2024-05-12T13:30:51.216018Z",
          "shell.execute_reply": "2024-05-12T13:30:51.230285Z"
        },
        "trusted": true,
        "id": "i2X5S9a3M4nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fun(eng_matrix,tel_matrix,batch_size,max_epochs,model):\n",
        "    correct=0\n",
        "#     print(batch_size)\n",
        "#     print(len(eng_matrix))\n",
        "    for batch_id in range((int)(len(eng_matrix)/batch_size)):\n",
        "        inp_word=eng_matrix[batch_size*batch_id:batch_size*(batch_id+1)].to(device=device)\n",
        "        out_word=tel_matrix[batch_size*(batch_id):batch_size*(batch_id+1)].to(device=device)\n",
        "        inp_word=inp_word.T\n",
        "        out_word=out_word.T\n",
        "        output=model.forward(inp_word,out_word,0)\n",
        "        output=nn.Softmax(dim=2)(output)\n",
        "        output=torch.argmax(output,dim=2)\n",
        "#         print(batch_id)\n",
        "#         print(batch_id,output)\n",
        "        output=output.T\n",
        "#         print(output)\n",
        "        out_word=out_word.T\n",
        "        for i in range(batch_size):\n",
        "#             print(output[batch_id*batch_size+i],tel_list_train[batch_id*batch_size+i])\n",
        "#             print(output[i],out_word[i])\n",
        "            if(torch.equal(output[i][1:],out_word[i][1:])):\n",
        "                correct=correct+1\n",
        "#                 print('hello',output[i][1:],out_word[i][1:])\n",
        "    return ((correct*100)/len(eng_matrix));"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T13:30:51.232323Z",
          "iopub.execute_input": "2024-05-12T13:30:51.232980Z",
          "iopub.status.idle": "2024-05-12T13:30:51.242665Z",
          "shell.execute_reply.started": "2024-05-12T13:30:51.232932Z",
          "shell.execute_reply": "2024-05-12T13:30:51.241996Z"
        },
        "trusted": true,
        "id": "5q9pVF9BM4nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bi_directional_bit=True\n",
        "enc_layers=3\n",
        "dec_layers=3\n",
        "batch_size=512\n",
        "embedding_size=256\n",
        "hidden_size=512\n",
        "enc_dropout=0\n",
        "dec_dropout=0\n",
        "max_epochs=60\n",
        "learning_rate=1e-3\n",
        "cell_type='GRU'\n",
        "attention_bit=True\n",
        "recurrent_neural_network(cell_type, bi_directional_bit, embedding_size, enc_dropout, dec_dropout, enc_layers, dec_layers, hidden_size, batch_size, attention, learning_rate, max_epochs,attention_bit)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T17:22:30.790220Z",
          "iopub.execute_input": "2024-05-12T17:22:30.790899Z"
        },
        "trusted": true,
        "id": "Ox9_gEkUM4nV",
        "outputId": "01d48683-6b05-425d-9eaa-5eedfd23e0a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "epoch:  0\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_34/3514724418.py:37: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n  torch.nn.utils.clip_grad_norm(model.parameters(),max_norm=1)\n100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(1.5785, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  0.099609375\nvalid accuracy:  0.5615234375\ntest accuracy:  0.5859375\nepoch:  1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.7154, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  15.634765625\nvalid accuracy:  20.99609375\ntest accuracy:  18.8232421875\nepoch:  2\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.3195, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  42.16015625\nvalid accuracy:  40.8935546875\ntest accuracy:  37.9638671875\nepoch:  3\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.2045, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  54.01171875\nvalid accuracy:  46.6796875\ntest accuracy:  43.7255859375\nepoch:  4\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  62.0078125\nvalid accuracy:  48.779296875\ntest accuracy:  45.7763671875\nepoch:  5\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.1175, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  67.01953125\nvalid accuracy:  51.26953125\ntest accuracy:  47.5830078125\nepoch:  6\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0880, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  73.65625\nvalid accuracy:  53.8818359375\ntest accuracy:  49.8779296875\nepoch:  7\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  76.572265625\nvalid accuracy:  53.9794921875\ntest accuracy:  49.2919921875\nepoch:  8\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0627, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  80.3828125\nvalid accuracy:  54.39453125\ntest accuracy:  49.365234375\nepoch:  9\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0509, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  79.416015625\nvalid accuracy:  53.1982421875\ntest accuracy:  47.75390625\nepoch:  10\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  84.0625\nvalid accuracy:  56.2255859375\ntest accuracy:  51.513671875\nepoch:  11\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0431, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  88.65625\nvalid accuracy:  55.6884765625\ntest accuracy:  51.0498046875\nepoch:  12\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  90.7421875\nvalid accuracy:  56.201171875\ntest accuracy:  51.904296875\nepoch:  13\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0261, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  89.01953125\nvalid accuracy:  55.37109375\ntest accuracy:  51.416015625\nepoch:  14\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0256, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  90.8515625\nvalid accuracy:  56.591796875\ntest accuracy:  52.8076171875\nepoch:  15\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0237, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  92.986328125\nvalid accuracy:  57.470703125\ntest accuracy:  53.2958984375\nepoch:  16\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0199, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  93.28515625\nvalid accuracy:  56.689453125\ntest accuracy:  52.1484375\nepoch:  17\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  95.109375\nvalid accuracy:  57.4462890625\ntest accuracy:  52.685546875\nepoch:  18\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0142, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  93.869140625\nvalid accuracy:  56.93359375\ntest accuracy:  52.978515625\nepoch:  19\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0113, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  96.607421875\nvalid accuracy:  58.3740234375\ntest accuracy:  52.6123046875\nepoch:  20\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [00:52<00:00,  1.89it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total loss:  tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>)\ntrain accuracy:  97.388671875\nvalid accuracy:  59.66796875\ntest accuracy:  53.466796875\nepoch:  21\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 99%|█████████▉| 99/100 [00:52<00:00,  1.86it/s]",
          "output_type": "stream"
        }
      ]
    }
  ]
}